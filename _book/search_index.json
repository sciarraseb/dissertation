[["1-introduction.html", "Is Timing Everything? The Effects of Measurement Timing on the Performance of Nonlinear Longitudinal Models Chapter 1 Introduction 1.1 The Need to Conduct Longitudinal Research 1.2 Understanding Patterns of Change That Emerge Over Time 1.3 Challenges Involved in Conducting Longitudinal Research 1.4 Using Simulations To Assess Modelling Accuracy 1.5 Systematic Review of Simulation Literature", " Is Timing Everything? The Effects of Measurement Timing on the Performance of Nonlinear Longitudinal Models Sebastian L.V. Sciarra February, 2023 Chapter 1 Introduction The topic of time has received considerable attention in organizational psychology over the past 20 years. Examples of well-received articles published around the beginning of the 21st century have discussed how investigating time is important for understanding patterns of change and boundary conditions of theory (Zaheer, Albert, and Zaheer 1999), how longitudinal research is necessary for disentangling different types of causality (T. R. Mitchell and James 2001), and explicated patterns of organizational change (or institutionalization; Lawrence, Winn, and Jennings 2001). Since then, articles have emphasized the need to address time in specific areas such as performance (C. D. Fisher 2008; Dalal, Bhave, and Fiset 2014), teams (Roe, Gockel, and Meyer 2012), and goal setting (Fried and Slowik 2004) and, more generally, throughout organizational research (George and Jones 2000; Roe 2008; Ployhart and Vandenberg 2010; Sonnentag 2012; Navarro, Roe, and Artiles 2015; Shipp and Cole 2015; Kunisch et al. 2017; Vantilborgh, Hofmans, and Judge 2018; Aguinis and Bakker 2021). The importance of time has also been recognized in organizational theory. In defining a theoretical contribution, Whetten (1989) discussed that time must be discussed in setting boundary conditions (i.e., under what circumstances does the theory apply) and in specifying relations between variables over time (T. R. Mitchell and James 2001; George and Jones 2000). Even if a considerable number of organizational theories do not adhere to the definition of Whetten (1989), theoretical models in organizational psychology consist of path diagrams that delineate the causal events of processes. Given that temporal precedence is a necessary condition for establishing causality (Mill 2011), time has a role, whether implicitly or explicitly, in organizational theory. Despite the considerable attention given towards investigating processes over time and the ubiquity of time in organizational theory, the prevalence of longitudinal research has historically remained low. One study examined the prevalence of longitudinal research from 1970–2006 across five organizational psychology journals and found that 4% of articles used longitudinal designs (Roe 2014, September 22–26). Another survey of two applied psychology journals in 2005 found that approximately 10% (10 of 105 studies) of studies used longitudinal designs (Roe 2008). Similarly, two surveys of studies employing longitudinal designs with mediation analysis found that, across five journals, only about 10% (7 of 72 studies) did so in 2005 (Maxwell and Cole 2007) and approximately 16% (15 of 92 studies) did so in 2006 (M. A. Mitchell and Maxwell 2013). Thus, the prevalence of longitudinal research has remained low. In the seven sections that follow, I will explain why longitudinal research is necessary and the factors that must be considered when conducting such research. In the first section, I will explain why conducting longitudinal research is essential for understanding the dynamics of psychological processes. In the second section, I will overview patterns of change that are likely to emerge over time. In the third section, I will overview design and analytical issues involved in conducting longitudinal studies. In the fourth section, I will explain how design and analytical issues encountered in conducting longitudinal research can be investigated. In the fifth section, I will provide a systematic review of the research that has investigated design and analytical issues involved in conducting longitudinal research. Finally, in the sixth and seventh sections, I will, respectively, discuss some methods for modelling nonlinear change and the frameworks in which they can be used. A summary of the three simulation experiments that I conducted in my dissertation will then be provided. 1.1 The Need to Conduct Longitudinal Research Longitudinal designs provide several advantages over cross-sectional designs that allow them to more accurately investigate change (e.g., temporal precedence, testing reverse causality). Unfortunately, even though longitudinal studies often produce results that differ from those of cross-sectional studies, researchers commonly discuss the results of cross-sectional studies as if they have been obtained with a longitudinal design. One example of the assumption of equivalence between cross-sectional and longitudinal findings comes from the large number of studies employing mediation analysis. Given that mediation is used to understand chains of causality in psychological processes (Baron and Kenny 1986), it would thus make sense to pair mediation analysis with a longitudinal design because understanding causality, after all, requires temporal precedence. Unfortunately, the majority of studies that have used mediation analysis have done so using cross-sectional designs—with estimates of approximately 90% (Maxwell and Cole 2007) and 84% (M. A. Mitchell and Maxwell 2013)—and often discuss the results as if they are longitudinal. Investigations into whether mediation results remain equivalent across cross-sectional and longitudinal designs have repeatedly concluded that using mediation analysis on cross-sectional data can return different, and sometimes completely opposite, results from using it on longitudinal data (Cole and Maxwell 2003; Maxwell and Cole 2007; Maxwell, Cole, and Mitchell 2011; M. A. Mitchell and Maxwell 2013; O’Laughlin, Martin, and Ferrer 2018). Therefore, mediation analyses based on cross-sectional analyses may be misleading. The non-equivalence of cross-sectional and longitudinal results that occurs with mediation analysis is, unfortunately, not due to a specific set of circumstances that only arise with mediation analysis, but a consequence of a broader systematic cause that affects the results of many analyses. The concept of ergodicity explains why cross-sectional and longitudinal analyses seldom yield similar results. To understand ergodicity, it is first important to realize that variance is central to many statistical analyses—correlation, regression, factor analysis, and mediation are some examples. Thus, if variance remains unchanged across cross-sectional and longitudinal data sets, then analyses of either data set would return the same results. Importantly, variance only remains equal across cross-sectional and longitudinal data sets if two conditions put forth by ergodic theory are satisfied (homogeneity and stationarity; Molenaar 2004; Molenaar and Campbell 2009). If these two conditions are met, then a process is said to be ergodic. Unfortunately, the two conditions required for ergodicity are highly unlikely to be satisfied and so cross-sectional findings will frequently deviate from longitudinal findings (for a detailed discussion, see Appendix \\(\\ref{ergodicity}\\)). Given that cross-sectional and longitudinal analyses are, in general, unlikely to return equivalent findings, it is unsurprising that several investigations in organizational research—and psychology as a whole—have found these analyses to return different results. Beginning with an example from Curran and Bauer (2011), heart attacks are less likely to occur in people who exercise regularly (longitudinal finding), but more likely to happen when exercising (cross-sectional finding). Correlational studies find differences in correlation magnitudes between cross-sectional and longitudinal data sets (for a meta-analytic review, see Nixon et al. 2011; A. J. Fisher, Medaglia, and Jeronimus 2018). Moving on to perhaps the most commonly employed analysis in organizational research of mediation, several articles have highlighted that cross-sectional data can return different, and sometimes completely opposite, results than those obtained from longitudinal data (Cole and Maxwell 2003; Maxwell and Cole 2007; Maxwell, Cole, and Mitchell 2011; O’Laughlin, Martin, and Ferrer 2018). Factor analysis is perhaps the most interesting example: The well-documented five-factor model of personality seldom arises when analyzing person-level data obtained by measuring personality on 90 consecutive days (Hamaker, Dolan, and Molenaar 2005). Therefore, cross-sectional analyses are rarely equivalent to longitudinal analyses. With longitudinal analyses often producing results that differ from those of cross-sectional analyses, it is paramount that longitudinal designs be used to more accurately understand change. Fortunately, technological advancements have allowed researchers to more easily conduct longitudinal research in two ways. First, the use of the experience sampling method (Beal 2015) in conjunction with modern information transmission technologies—whether through phone applications or short message services—allows data to often be sampled over time with relative ease. Second, the development of longitudinal analyses (along with their integration in commonly used software) that enable person-level data to be modelled such as multilevel models (Raudenbush and Bryk 2002), growth mixture models (Mo Wang and Bodner 2007), and dynamic factor analysis (Ram, Brose, and Molenaar 2013) provide researchers with avenues to explore the temporal dynamics of psychological processes. With one recent survey estimating that 43.3% of mediation studies (26 of 60 studies) used a longitudinal design (O’Laughlin, Martin, and Ferrer 2018), it appears that the prevalence of longitudinal research has increased from the 9.5% (Roe 2008) and 16.3% (M. A. Mitchell and Maxwell 2013) values estimated at the beginning of the 21st century. Although the frequency of longitudinal research appears to have increased over the past 20 years, several avenues exist where the quality of longitudinal research can be improved, and in my dissertation, I focus on investigating these avenues. 1.2 Understanding Patterns of Change That Emerge Over Time Change can occur in many ways over time. One pattern of change commonly assumed to occur over time is that of linear change. When change follows a linear pattern, the rate of change over time remains constant. Unfortunately, a linear pattern places demanding restrictions on the possible trajectories of change. If change were to follow a linear pattern, then any pauses in change (or plateaus) or changes in direction could not occur: Change would simply grow over time. Unfortunately, effect sizes have been shown to diminish over time after peaking (for meta-analytic examples, see Cohen 1993; Griffeth, Hom, and Gaertner 2000; Hom et al. 1992; Riketta 2008; Steel and Ovalle 1984; Steel, Hendrix, and Balogh 1990). Moreover, many variables display cyclic patterns of change over time, with mood (Larsen and Kasimatis 1990), daily stress (Bodenmann et al. 2010), and daily drinking behaviour (Huh, Kaysen, and Atkins 2015) as some examples. Therefore, change over is unlikely to follow a linear pattern. A more realistic pattern of change to occur over time is a nonlinear pattern (for a review, see Cudeck and Harring 2007). Nonlinear change allows the rate of change to be nonconstant; that is, change may occur more rapidly during certain periods of time, stop altogether, or reverse direction. When looking at patterns of change observed across psychology, several examples of nonlinear change have been found in the declining rate of speech errors throughout child development (Burchinal and Appelbaum 1991), rates of forgetting (Murre and Dros 2015), development of habits (Fournier et al. 2017), and the formation of opinions (Xia et al. 2020). Given that nonlinear change appears more likely than linear change, my dissertation will assume change over time to be nonlinear. 1.3 Challenges Involved in Conducting Longitudinal Research Conducting longitudinal research presents researchers with several challenges. Many challenges are those from cross-sectional research only amplified (for a review, see Bergman and Magnusson 1990). For example, greater efforts have to be made to to prevent missing data which can increase over time (Newman 2008; Dillman, Smyth, and Christian 2014). Likewise, the adverse effects of well-documented biases such as demand characteristics (Orne 1962) and social desirability (Nederhof 1985) have to be countered at each time point. Outside of challenges shared with cross-sectional research, conducting longitudinal research also presents new challenges. Analyses of longitudinal data have to consider complications such as how to model error structures (Grimm and Widaman 2010), check for measurement non-invariance over time (the extent to which a construct is measured with the same measurement model over time; Mellenbergh 1989), and how to center/process data to appropriately answer research questions (Enders and Tofighi 2007; Wang and Maxwell 2015). Although researchers must contend with several issues in conducting longitudinal research, three issues are of particular interest in my dissertation. The first issue concerns how many measurements to use in a longitudinal design. The second issue concerns how to space the measurements. The third issue focuses on how much error is incurred if the time structuredness of the data is overlooked. The sections that follow will review each of these issues. 1.3.1 Number of Measurements Researchers have to decide on the number of measurements to include in a longitudinal study. Although using more measurements increases the accuracy of results—as noted in the results of several studies (e.g., Coulombe, Selig, and Delaney 2016; Timmons and Preacher 2015; Finch 2017; Fine, Suk, and Grimm 2019)—taking additional measurements often comes at a cost that a researcher may be unable to absorb given a limited budget. One important point to mention is that a researcher designing a longitudinal study must take at least three measurements to allow a reliable estimate of change and, perhaps more importantly, to allow a nonlinear pattern of change to be modelled (Ployhart and Vandenberg 2010). In my dissertation, I hope to determine whether an optimal number of measurements exists when modelling a nonlinear pattern of change. 1.3.2 Spacing of Measurements Additionally, a researcher must decide on the spacing of measurements in a longitudinal study. Although discussions of measurement spacing often recommend that researchers use theory and previous studies to determine measurement spacing (T. R. Mitchell and James 2001; Cole and Maxwell 2003; Collins 2006; Dormann and Ven 2014; Dormann and Griffin 2015), organizational theories seldom delineate periods of time over which a processes unfold, and so the majority of longitudinal research uses intervals of convention and/or convenience to space measurements (T. R. Mitchell and James 2001; Dormann and Ven 2014). Unfortunately, using measurement spacings that do not account for the temporal pattern of change of a psychological process can lead to inaccurate results (e.g., Chen, Martin, and Merchant 2014). As an example, Cole and Maxwell (2009) show how correlation magnitudes are affected by the choice of measurement spacing intervals. In my dissertation, I hope to determine whether an optimal measurement spacing schedule exists when modelling a nonlinear pattern of change. 1.3.3 Time Structuredness Last, and perhaps most pernicious, latent variable analyses of longitudinal data are likely to incur error from an assumption they make about data collection conditions. Latent variable analyses assume that, across all collection points, participants provide their data at the same time. Unfortunately, such a high level of regularity in the response patterns of participants is unlikely: Participants are more likely to provide their data over some period of time after a data collection window has opened. As an example, consider a study that collects data from participants at the beginning of each month. If participants respond with perfect regularity, then they would all provide their data at the exact same time (e.g., noon on the second day of each month). If the participants respond with imperfect regularity, then they would provide their at different times after the beginning of each month. The regularity of response patterns observed across participants in a longitudinal study determines the time structuredness of the data and the sections that follow will provide overview of time structuredness. 1.3.3.1 Time-Structured Data Many analyses assume that data are time structured: Participants provide data at the same time at each collection point. By assuming time-structured data, an analysis can incur error because it will map time intervals of inappropriate lengths onto the time intervals that occurred between participant’s responses. As an example of the consequences of incorrectly assuming data to be time structured, consider a study that assessed the effects of an intervention on the development of leadership by collecting leadership ratings at four time points each separated by four weeks (Day and Sin 2011). The employed analysis assumed time-structured data; that is, each each participant provided ratings on the same day—more specifically, the exact same moment—each time these ratings were collected. Unfortunately, it is unlikely that the data collected from participants were time structured: At any given collection point, some participants may have provided leadership ratings at the beginning of the week, while others may only provide ratings two weeks after the survey opened. Importantly, ratings provided two weeks after the survey opened were likely influenced by changes in leadership that occurred over the two weeks. If an analysis incorrectly assumes time-structured data, then it assumes each participant has the same response pattern and, therefore, will incorrectly attribute the amount of time that elapses between most participants’ responses. For instance, if a participant only provides a leadership rating two weeks after having received a survey (and six weeks after providing their previous rating), then using an analysis that assumes time-structured data would incorrectly assume that each collection point of this participant is separated by four weeks (the interval used in the experiment) and would, consequently, model the observed change as if it had occurred over four weeks. Therefore, incorrectly assuming data to be time structured leads an analysis to overlook the unique response rates of participants across the collection points and, as a consequence, incur error (Mehta and West 2000; Mehta and Neale 2005; Coulombe, Selig, and Delaney 2016). 1.3.3.2 Time-Unstructured Data Conversely, other analyses assume that data are time unstructured: Participants provide data at different times at each collection point. Given the unlikelihood of one response pattern describing the response rates of all participants in a given study, the data obtained in a study are unlikely to be time structured. Instead, and because participants are likely to exhibit unique response patterns in their response rates, data are likely to be time unstructured. One way to conceptualize the distinction between time-structured and time-unstructured data is on a continuum. On one end of the continuum, participants all provide data with identical response patterns, thus giving time-structured data. When participants exhibit unique response patterns, the resulting data are time unstructured, with the extent of time-unstructuredness depending on the average uniqueness of all response patterns. For example, if data are collected at the beginning of each month and participants only have one day to provide data at each time point, then the resulting data will have a low amount of time structuredness because response patterns can only differ from each other over the course of one day. Alternatively, if data are collected at the beginning of each month and participants have 30 days to provide data at each time point, then the resulting data will have a high amount of time structuredness because response patterns can differ from each other over the course of 30 days. Therefore, the continuum of time struturedness has time-structured data on one end and time-unstructured data with long response windows on another end. In my dissertation, I hope to determine how much error is incurred when time-unstructured data of varying degrees are assumed to be time structured. 1.3.4 Summary In summary, researchers must contend with several issues when conducting longitudinal research. In addition to contending with issues encountered in conducting cross-sectional research, researchers must contend with new issues that arise from conducting longitudinal research. Three issues of particular importance in my dissertation are the number of measurements, the spacing of measurements, and incorrectly assuming time-unstructured data to be time structured. These issues will be serve as a basis for a systematic review of the simulation literature. 1.4 Using Simulations To Assess Modelling Accuracy In the next section, I will present the results of a systematic review of the literature that has investigated the issues of measurement number, measurement spacing, and time structuredness. Before presenting the results of the systematic review, I will provide an overview of the Monte Carlo method used to investigate the issues involved in conducting longitudinal research. To understand how the effects of longitudinal issues on modelling accuracy can be investigated, the inferential method commonly employed in psychological research will first be reviewed with an emphasis on its shortcomings (see Figure \\(\\ref{fig:MonteCarlo-comparison}\\)). Consider an example where a researcher wants to understand how sampling error affects the accuracy with which a sample mean (\\(\\bar{x}\\)) estimates a population mean (\\(\\upmu\\)). Using the inferential method, the researcher samples data and then estimates the population mean (\\(\\upmu\\)) by computing the mean of the sampled data (\\(\\bar{x}_1\\)). Because collected samples are almost always contaminated by a variety of methodological and/or statistical deficiencies (such as sampling error, measurement error, assumption violations, etc.), the estimation of the population parameter is likely to be imperfect. Unfortunately, to estimate the effect of sampling error on the accuracy of the population mean estimate (\\(\\bar{x}_1\\)), the researcher would need to know the value of the population mean; without knowing the value of the population mean, it is impossible to know how much error was incurred in estimating the population mean and, as as a result, impossible to know the extent to which sampling error contributed to this error. Therefore, a study following the inferential approach can only provide estimates of population parameters. The Monte Carlo method has a different goal. Whereas the inferential method focuses on estimating parameters from sample data, the Monte Carlo method is used to understand the factors that influence the accuracy of the inferential approach. Figure \\(\\ref{fig:MonteCarlo-comparison}\\) shows that the Monte Carlo method works in the opposite direction of the inferential approach: Instead of collecting a sample, the Monte Carlo method begins by assigning a value to at least one parameter to define a population. Many sample data sets are then generated from the defined population (\\(s_1, s_2, ..., s_n\\)) and the data from each sample are then modelled by computing a sample mean (\\(\\bar{x}_1, \\bar{x}_2, ..., \\bar{x}_n\\)). Importantly, manipulations can be applied to the sampling and/or modelling of the data. In the current example,the population estimates of each statistical model are averaged (\\(\\bar{\\bar{x}}\\)) and compared to the pre-determined parameter value (\\(\\upmu\\)). The difference between the average of the estimates and the known population value constitutes bias in parameter estimation (i.e., parameter bias). In the current example, the manipulation causes a systematic underestimation, on average, of the population parameter. By randomly generating data, the Monte Carlo method can estimate how a variety of methodological and statistical factors affect the accuracy of a model (for a review, see Robert and Casella 2010). Monte Carlo simulations have been used to evaluate the effects of a variety of methodological and statistical deficiencies for several decades. Beginning with an early use of the Monte Carlo method, Boneau (1960) used it to evaluate the effects of assumption violations on the fidelity of t-value distributions. In more recent years, implementations of the the Monte Carlo method have shown that realistic values of sample size and measurement accuracy produce considerable variability in estimated correlation values (Stanley and Spence 2014). Monte Carlo simulations have also provided valuable insights into more complicated statistical analyses. In investigating more complex statistical analyses, simulations have shown that mediation analyses are biased to produce results of complete mediation because the statistical power to detect direct effects falls well below the statistical power to detect indirect effects (Kenny and Judd 2014). Given the ability of the Monte Carlo method to evaluate statistical methods, the experiments in my dissertation used it to evaluate the effects of measurement number, measurement spacing, and time structuredness on modelling accuracy. 1.5 Systematic Review of Simulation Literature To understand the extent to which issues involved in conducting longitudinal research had been investigated, I conducted a systematic review of the simulation literature. The sections that follow will first present the method I followed in systematically reviewing the literature and then summarize the findings of the review. 1.5.1 Systematic Review Methodology I identified the following keywords through citation searching and independent reading: “growth curve”, “time-structured analysis”, “time structure”, “temporal design”, “individual measurement occasions”, “measurement intervals”, “methods of timing”, “longitudinal data analysis”, “individually-varying time points”, “measurement timing”, “latent difference score models”, “parameter bias”, and “measurement spacing”. I entered these keywords entered into the PsycINFO database (on July 23, 2021) along with the word “simulation” in any field and considered any returned paper a viable ppaper (see Figure \\(\\ref{fig:prismaDiagram}\\) for a PRISMA diagram illustrating the filtering of the reports). The search returned 165 reports, which I screened by reading the abstracts. Initial screening led to the removal of 60 reports because they did not contain any simulation experiments. Of the remaining 105 papers, I removed 2 more papers because they could not be accessed (Stockdale 2007; Tiberio 2008). Of the remaining 103 identified simulation studies, I deemed a paper as relevant if it investigated the effects of any design and/or analysis factor related to conducting longitudinal research (i.e., number of measurements, spacing of measurements, and/or time structuredness) and did so using the Monte Carlo simulation method. Of the remaining 103 studies, I removed 89 studies because they did not meet the inclusion criteria, leaving fourteen studies to be included in the review. I also found an additional 3 studies through citation searching, giving a total of 17 studies. The findings of my systematic review are summarized in Tables \\(\\ref{tab:systematicReviewCount}\\)–??. Tables \\(\\ref{tab:systematicReviewCount}\\)–?? differ in one way: Table \\(\\ref{tab:systematicReviewCount}\\) indicates how many studies investigated each effect, whereas Table ?? provides the reference of each study and detailed information about each study’s method. Otherwise, all other details of Tables \\(\\ref{tab:systematicReviewCount}\\)–?? are identical. The first column lists the longitudinal design factor (alongside with sample size) and the corresponding two- and three-way interactions. The second and third columns list whether each effect has been investigated with linear and nonlinear patterns of change, respectively. Shaded cells indicate effects that have not been investigated, with cells shaded in light grey indicating effects that have not been investigated with linear patterns of change and cells shaded in dark grey indicating effects that have not been investigated with nonlinear patterns of change. 1.5.2 Systematic Review Results Although previous research appeared to sufficiently fill some cells of Table \\(\\ref{tab:systematicReviewCount}\\), two patterns suggest that arguably the most important cells (or effects) have not been investigated. First, it appears that simulation research has invested more effort in investigating the effects of longitudinal design factors with linear patterns than with nonlinear patterns of change. In counting the number of effects that remain unaddressed with linear and nonlinear patterns of change, a total of five cells (or effects) have not been investigated, but a total of seven cells have not been investigated with nonlinear patterns of "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
